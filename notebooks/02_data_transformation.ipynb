{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion de datos\n",
    "En este notebook se aplicaran las transformaciones identificadas y propuestas en el notebook *01_celan_var.ipynb*, esto con el fin de obtener un dataset de train y test listo para utilizar en el modelo de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can safely assume that `build_dataset` is correctly implemented\n",
    "def build_dataset():\n",
    "    data = [json.loads(x) for x in open(\"../data/MLA_100k.jsonlines\")]\n",
    "    target = lambda x: x.get(\"condition\")\n",
    "    N = -10000\n",
    "    X_train = data[:N]\n",
    "    X_test = data[N:]\n",
    "    y_train = [target(x) for x in X_train]\n",
    "    y_test = [target(x) for x in X_test]\n",
    "\n",
    "    df_X_train = pd.json_normalize(X_train, sep='_')\n",
    "    df_X_test = pd.json_normalize(X_test, sep='_')\n",
    "\n",
    "    df_X_test = df_X_test.loc[:,df_X_train.columns.values]\n",
    "    df_X_test.drop(columns=\"condition\", inplace=True)\n",
    "\n",
    "    # for x in X_test:\n",
    "    #     del x[\"condition\"]\n",
    "\n",
    "\n",
    "    return df_X_train, y_train, df_X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones transformacion\n",
    "a continuacion se definen funciones que ayudan a procesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df,lst_cols):\n",
    "    drop_df = df.drop(columns=lst_cols)\n",
    "    return drop_df\n",
    "\n",
    "def to_binary_exists(df,cols):\n",
    "    df[cols] = (~df[cols].isna()).astype(int)\n",
    "    return df\n",
    "\n",
    "def rename_cols_to_binary_exists(df,dict_cols):\n",
    "    df.rename(columns=dict_cols, inplace=True)\n",
    "    df = to_binary_exists(df, list(dict_cols.values()))\n",
    "\n",
    "    return df\n",
    "\n",
    "def to_binary_boolean_to_numeric(df,cols):\n",
    "    df[cols] = df[cols].astype(int).fillna(0)\n",
    "    return df\n",
    "\n",
    "def to_binary_exists_json(df,cols):\n",
    "    df[cols] = df[cols].apply(lambda x : (x.str.len().fillna(0) > 0).astype(int))\n",
    "    return df\n",
    "\n",
    "def to_binary_str_is_in(df,dict_transform):\n",
    "    for column, (values, custom_name) in dict_transform.items():\n",
    "        if len(values) == 1 and custom_name is None:\n",
    "            column_name = f\"flg_{column}_{values[0]}\".replace(\" \", \"_\")\n",
    "        else:\n",
    "            column_name = f\"flg_{custom_name}\".replace(\" \", \"_\")\n",
    "        # Create binary flag column with the custom name\n",
    "        df[column_name] = df[column].isin(values).astype(int).fillna(0)\n",
    "    \n",
    "    # Drop the original columns\n",
    "    df.drop(columns=dict_transform.keys(), inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform_get_variation(df, base_column, compare_column, new_column):\n",
    "    df[new_column] = (np.sign(df[base_column] - df[compare_column])).fillna(0)\n",
    "    df.drop(columns=[compare_column], inplace=True)\n",
    "    return df\n",
    "\n",
    "def transform_num_elements_json(df,dict_transformations,drop=True):\n",
    "    for original_column, config in dict_transformations.items():\n",
    "            if isinstance(config, tuple):\n",
    "                new_column, drop = config\n",
    "            else:\n",
    "                new_column, drop = config, drop\n",
    "\n",
    "            df[new_column] = df[original_column].str.len().fillna(0)\n",
    "            \n",
    "            if drop:\n",
    "                df.drop(columns=[original_column], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform_payment_methods(df,drop=True):\n",
    "    dict_metodos_de_pago = {\n",
    "        \"Acordar con el comprador\": \"efectivo_o_acuerdo\",\n",
    "        \"Efectivo\": \"efectivo_o_acuerdo\",\n",
    "        \"Transferencia bancaria\": \"transferencia_bancaria\",\n",
    "        \"Giro postal\": \"giro_postal\",\n",
    "        \"Cheque certificado\": \"cheque\",\n",
    "        \"American Express\": \"tarjeta_credito\",\n",
    "        \"Diners\": \"tarjeta_credito\",\n",
    "        \"MasterCard\": \"tarjeta_credito\",\n",
    "        \"Mastercard Maestro\": \"tarjeta_credito\",\n",
    "        \"Visa\": \"tarjeta_credito\",\n",
    "        \"Visa Electron\": \"tarjeta_credito\",\n",
    "        \"Tarjeta de cr√©dito\": \"tarjeta_credito\",\n",
    "        \"MercadoPago\": \"MercadoPago\",\n",
    "        \"Contra reembolso\": \"contra_reembolso\"\n",
    "    }\n",
    "    \n",
    "    df_payment_methods = df.loc[:,[\"id\",\"non_mercado_pago_payment_methods\"]].\\\n",
    "                            explode(\"non_mercado_pago_payment_methods\").\\\n",
    "                            reset_index()\n",
    "\n",
    "    df_payment_methods_explode = pd.json_normalize(df_payment_methods[\"non_mercado_pago_payment_methods\"])\n",
    "    df_payment_methods_explode.rename(columns={\"description\":\"description_shipping_free_methods\",\n",
    "                                                    \"id\":\"id_shipping_free_methods\"},\n",
    "                                            inplace=True)\n",
    "\n",
    "    df_payment_methods = pd.concat([df_payment_methods[[\"id\"]], \n",
    "                                        df_payment_methods_explode], \n",
    "                                        axis=1)[[\"id\",\"description_shipping_free_methods\",\"id_shipping_free_methods\"]]\n",
    "    \n",
    "\n",
    "    df_payment_methods[\"metodo_de_pago\"] = df_payment_methods[\"description_shipping_free_methods\"].map(dict_metodos_de_pago)\n",
    "    df_payment_methods[\"ones\"] = 1\n",
    "    gr_df_payment_methods = df_payment_methods.groupby([\"id\",\"metodo_de_pago\"])[[\"ones\"]].sum().reset_index()\n",
    "    gr_df_payment_methods = gr_df_payment_methods.pivot(index=\"id\",columns=\"metodo_de_pago\", values=\"ones\").fillna(0)\n",
    "\n",
    "    df = pd.merge(df, gr_df_payment_methods, on=\"id\", how=\"left\").fillna(0)\n",
    "    df.loc[:,gr_df_payment_methods.columns.values] = df[gr_df_payment_methods.columns.values].fillna(0)\n",
    "\n",
    "    if drop:\n",
    "        df.drop(columns=[\"non_mercado_pago_payment_methods\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform_listing_type(df):\n",
    "    dict_transform_listing_type = {'free':0,\n",
    "                               'bronze':1,\n",
    "                               'silver':2,\n",
    "                               'gold':3, \n",
    "                               'gold_premium':4,\n",
    "                               'gold_special':5, \n",
    "                               'gold_pro':6}\n",
    "    \n",
    "    df[\"listing_type_id\"] = df[\"listing_type_id\"].map(dict_transform_listing_type).fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers \n",
    "a continuacion se definen transformadores personalizados ya que estos deben realizar un calculo a partir de los datos de entrenamiento y almacenar los valores para posteriormente ser aplicados a datos futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sellerIdTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_column=True):\n",
    "        self.drop_column = drop_column\n",
    "        self.dict_seller = None\n",
    "\n",
    "    def fit(self,X, y=None):\n",
    "        X_copy = X[[\"id\",\"seller_id\",\"condition\"]].copy()\n",
    "        X_copy[\"binary_used\"] = (X_copy[\"condition\"] == \"used\").astype(int)\n",
    "\n",
    "        gr_seller_id = X_copy.groupby([\"seller_id\"]).agg({\"binary_used\":\"sum\",\"id\":\"count\"})\n",
    "        gr_seller_id[\"score_seller_used\"] = gr_seller_id[\"binary_used\"]/gr_seller_id[\"id\"]\n",
    "\n",
    "        self.dict_seller = gr_seller_id[[\"score_seller_used\"]].to_dict()[\"score_seller_used\"]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        if self.dict_seller is None:\n",
    "            raise ValueError(\"El transformador no ha sido entrenado, ejecute la funcion 'fit' primero.\")\n",
    "        \n",
    "        X_copy = X.copy()\n",
    "        X_copy[\"score_seller\"] = X_copy[\"seller_id\"].map(self.dict_seller).fillna(0)\n",
    "        \n",
    "        if self.drop_column:\n",
    "            X_copy.drop(columns=[\"seller_id\"], inplace=True)\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "class CategoryIdPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_category_id=True):\n",
    "        self.drop_category_id = drop_category_id\n",
    "        self.dict_category_popularity = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X[[\"id\",\"category_id\",\"condition\"]].copy()\n",
    "\n",
    "        X_copy[\"binary_used\"] = (X_copy[\"condition\"] == \"used\").astype(int)\n",
    "\n",
    "        gr_seller_id = X_copy.groupby(\"category_id\").agg({\"binary_used\": \"sum\", \"id\": \"count\"})\n",
    "        gr_seller_id[\"score_category_used\"] = gr_seller_id[\"binary_used\"] / gr_seller_id[\"id\"]\n",
    "\n",
    "        self.dict_category_popularity = gr_seller_id[\"score_category_used\"].to_dict()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.dict_category_popularity is None:\n",
    "            raise ValueError(\"El transformador no ha sido entrenado, ejecute la funcion 'fit' primero.\")\n",
    "\n",
    "        # Map the category_id to its score\n",
    "        X_copy = X.copy()\n",
    "        X_copy[\"score_popularity_category\"] = X_copy[\"category_id\"].map(self.dict_category_popularity).fillna(0)\n",
    "\n",
    "        # Drop unnecessary columns if specified\n",
    "        if self.drop_category_id:\n",
    "            X_copy.drop(columns=[\"category_id\"], inplace=True)\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "class CategoryIdTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_category_id=True):\n",
    "        self.drop_category_id = drop_category_id\n",
    "        self.dict_category = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        gr_category_id = X.groupby(\"category_id\")[[\"id\"]].count().sort_values(\"id\",ascending=False)\n",
    "        gr_category_id = gr_category_id/gr_category_id.max()\n",
    "\n",
    "        self.dict_category = gr_category_id.to_dict()[\"id\"]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.dict_category is None:\n",
    "            raise ValueError(\"El transformador no ha sido entrenado, ejecute la funcion 'fit' primero.\")\n",
    "\n",
    "        # Map the category_id to its score\n",
    "        X_copy = X.copy()\n",
    "        X_copy[\"score_category_id\"] = X_copy[\"category_id\"].map(self.dict_category).fillna(0)\n",
    "\n",
    "        # Drop unnecessary columns if specified\n",
    "        if self.drop_category_id:\n",
    "            X_copy.drop(columns=[\"category_id\"], inplace=True)\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "class FlgOutlierTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lst_columns):\n",
    "        self.dict_upper_lower_bounds = None\n",
    "        self.lst_columns = lst_columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Create a binary column for used condition\n",
    "        \n",
    "        dict_param_outliers = {}\n",
    "        q1 = X[self.lst_columns].quantile(0.25)\n",
    "        q3 = X[self.lst_columns].quantile(0.75)\n",
    "        \n",
    "        # Calculate IQR\n",
    "        iqr = q3 - q1\n",
    "        \n",
    "        # Define lower and upper bounds\n",
    "        lower_bounds = q1 - 1.5 * iqr\n",
    "        upper_bounds = q3 + 1.5 * iqr\n",
    "        \n",
    "        # Combine into a dictionary\n",
    "        self.dict_upper_lower_bounds = {col: [lower_bounds[col], upper_bounds[col]] for col in self.lst_columns}\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.lst_columns is None:\n",
    "            raise ValueError(\"El transformador fue inicializado incorrectamente, suministre una lista de columnas como parametro de entrada\")\n",
    "        if self.dict_upper_lower_bounds  is None:\n",
    "            raise ValueError(\"El transformador no ha sido entrenado, ejecute la funcion 'fit' primero.\")\n",
    "        \n",
    "        lower_bounds = pd.Series({col: bounds[0] for col, bounds in self.dict_upper_lower_bounds.items()})\n",
    "        upper_bounds = pd.Series({col: bounds[1] for col, bounds in self.dict_upper_lower_bounds.items()})\n",
    "\n",
    "        is_outlier = (X[self.lst_columns] < lower_bounds) | (X[self.lst_columns] > upper_bounds)\n",
    "        outlier_flags = is_outlier.astype(int).add_prefix(\"flg_outliers_\")\n",
    "\n",
    "        # Combine the original DataFrame with the outlier flags\n",
    "        X_transformed = pd.concat([X, outlier_flags], axis=1)\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 lst_drop_cols, \n",
    "                 lst_binary_exists, \n",
    "                 lst_binary_boolean_to_numeric, \n",
    "                 lst_json_binary, \n",
    "                 dict_transform_str_is_in, \n",
    "                 dict_inmobiliario, \n",
    "                 dict_transform_num_elements, \n",
    "                 lst_outliers):\n",
    "\n",
    "        self.lst_drop_cols = lst_drop_cols\n",
    "        self.lst_binary_exists = lst_binary_exists\n",
    "        self.lst_binary_boolean_to_numeric = lst_binary_boolean_to_numeric\n",
    "        self.lst_json_binary = lst_json_binary\n",
    "        self.dict_transform_str_is_in = dict_transform_str_is_in\n",
    "        self.dict_inmobiliario = dict_inmobiliario\n",
    "        self.dict_transform_num_elements = dict_transform_num_elements\n",
    "        self.lst_outliers = lst_outliers\n",
    "        \n",
    "        \n",
    "        # Initialize sub-transformers\n",
    "        self.trans_seller_id = sellerIdTransformer()\n",
    "        self.trans_categ_id_popularity = CategoryIdPopularityTransformer(drop_category_id=False)\n",
    "        self.trans_categ_id = CategoryIdTransformer()\n",
    "        self.trans_flg_outliers = FlgOutlierTransformer(lst_columns=lst_outliers)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.trans_seller_id.fit(X, y)\n",
    "        self.trans_categ_id_popularity.fit(X, y)\n",
    "        self.trans_categ_id.fit(X, y)\n",
    "        self.trans_flg_outliers.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "\n",
    "        # Apply transformations\n",
    "        df = drop_cols(df, self.lst_drop_cols)\n",
    "        df = to_binary_exists(df, self.lst_binary_exists)\n",
    "        df = to_binary_boolean_to_numeric(df, self.lst_binary_boolean_to_numeric)\n",
    "        df = to_binary_exists_json(df,self.lst_json_binary)\n",
    "        df = to_binary_str_is_in(df, self.dict_transform_str_is_in)\n",
    "        df = rename_cols_to_binary_exists(df, self.dict_inmobiliario)\n",
    "\n",
    "        df = transform_get_variation(df, base_column=\"price\", compare_column=\"base_price\", new_column=\"variation_base_price\")\n",
    "        df = transform_get_variation(df, base_column=\"price\", compare_column=\"original_price\", new_column=\"variation_original_price\")\n",
    "        df = transform_get_variation(df, base_column=\"initial_quantity\", compare_column=\"available_quantity\", new_column=\"variation_available_quantity\")\n",
    "\n",
    "        df = transform_payment_methods(df, drop=False)\n",
    "        df = transform_num_elements_json(df, self.dict_transform_num_elements)\n",
    "\n",
    "        df = transform_listing_type(df)\n",
    "\n",
    "        # Apply sub-transformers\n",
    "        df = self.trans_seller_id.transform(df)\n",
    "        df = self.trans_categ_id_popularity.transform(df)\n",
    "        df = self.trans_categ_id.transform(df)\n",
    "        df = self.trans_flg_outliers.transform(df)\n",
    "\n",
    "        # Drop 'condition' column if it exists\n",
    "        if 'condition' in df.columns:\n",
    "            df.drop(columns=['condition'], inplace=True)\n",
    "\n",
    "        if 'id' in df.columns:\n",
    "            df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura\n",
    "df_X_train, y_train, df_X_test, y_test = build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_drop_cols = [\"thumbnail\",\n",
    "                 \"secure_thumbnail\",\n",
    "                 \"permalink\",\n",
    "                 \"site_id\",\n",
    "                 \"location_country_id\",\n",
    "                 \"location_country_name\",\n",
    "                 \"international_delivery_mode\",\n",
    "                 \"seller_contact\",\n",
    "                 \"location_zip_code\",\n",
    "                 \"differential_pricing\",\n",
    "                 \"location_open_hours\",\n",
    "                 \"subtitle\",\n",
    "                 \"listing_source\",\n",
    "                 \"seller_contact_webpage\",\n",
    "                 \"catalog_product_id\",\n",
    "                 \"shipping_dimensions\",\n",
    "                 \"seller_contact_phone2\",\n",
    "                 \"seller_contact_area_code2\",\n",
    "                 \"seller_contact_other_info\",\n",
    "                 \"coverage_areas\",\n",
    "                 \"shipping_methods\",\n",
    "                 \"shipping_tags\",\n",
    "                 \"deal_ids\",\n",
    "                 \"seller_address_country_id\",\n",
    "                 \"seller_address_search_location_neighborhood_id\",\n",
    "                 \"seller_address_search_location_state_id\",\n",
    "                 \"seller_address_search_location_city_id\",\n",
    "                 \"seller_address_city_id\",\n",
    "                 \"seller_address_state_id\",\n",
    "                 \"location_neighborhood_id\",\n",
    "                 \"location_city_id\",\n",
    "                 \"location_state_id\",\n",
    "                 \"geolocation_latitude\",\n",
    "                 \"geolocation_longitude\",\n",
    "                 \"seller_address_latitude\",\n",
    "                 \"seller_address_longitude\",\n",
    "                 \"seller_address_search_location_state_name\",\n",
    "                 \"seller_address_id\",\n",
    "                 \"seller_address_search_location_city_name\",\n",
    "                 \"last_updated\",\n",
    "                 \"start_time\",\n",
    "                 \"stop_time\",\n",
    "                 \"date_created\",\n",
    "                 \"descriptions\",\n",
    "                 \"seller_address_comment\",\n",
    "                 \"seller_address_address_line\",\n",
    "                 \"title\",\n",
    "                 \"seller_address_city_name\",\n",
    "                 \"seller_address_zip_code\",\n",
    "                 \"seller_address_search_location_neighborhood_name\",\n",
    "                 \"sub_status\",\n",
    "                 \"status\",\n",
    "                 \"currency_id\",\n",
    "                 \"seller_address_country_name\",\n",
    "                 \"seller_contact_contact\",\n",
    "                 \"seller_contact_area_code\",\n",
    "                 \"seller_contact_phone\",\n",
    "                 \"location_neighborhood_name\",\n",
    "                 \"location_longitude\",\n",
    "                 \"location_address_line\",\n",
    "                 \"location_latitude\",\n",
    "                 \"location_city_name\",\n",
    "                 \"location_state_name\"]\n",
    "\n",
    "#transformacioness\n",
    "lst_binary_boolean_to_numeric = [\"accepts_mercadopago\", \n",
    "                                    \"automatic_relist\", \n",
    "                                    \"shipping_local_pick_up\",\n",
    "                                    \"shipping_free_shipping\"\n",
    "                                ]\n",
    "\n",
    "lst_binary_exists = [\"warranty\",\n",
    "                        \"parent_item_id\", \n",
    "                        \"official_store_id\",\n",
    "                        \"video_id\"\n",
    "                        ]\n",
    "\n",
    "lst_json_binary = [\"shipping_free_methods\"]\n",
    "\n",
    "\n",
    "dict_transform_str_is_in = {\"buying_mode\":([\"buy_it_now\"],None),\n",
    "                            \"shipping_mode\":([\"not_specified\"],None),\n",
    "                            \"seller_address_state_name\":([\"capital federal\"],None)}\n",
    "\n",
    "\n",
    "\n",
    "dict_inmobiliario = {\"seller_contact_email\":\"flg_inmobiliario\"}\n",
    "\n",
    "dict_transform_num_elements = {\n",
    "        \"variations\": \"num_variations\",\n",
    "        \"attributes\": \"num_attributes\",\n",
    "        \"tags\":\"num_tags\",\n",
    "        \"pictures\": \"num_pictures\",\n",
    "        \"non_mercado_pago_payment_methods\":\"num_payment_methods\"\n",
    "    }\n",
    "\n",
    "list_variaciones = [\"base_price\",\"original_price\"]\n",
    "\n",
    "lst_scores = [\"seller_id\",\"category_id\"]\n",
    "\n",
    "lst_recategorizacion = [\"listing_type_id\",\n",
    "                        \"non_mercado_pago_payment_methods\"]\n",
    "\n",
    "lst_correlacion = [\"available_quantity\"]\n",
    "\n",
    "lst_outliers = ['price', 'initial_quantity', 'sold_quantity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_dataset = DatasetTransformer(\n",
    "                 lst_drop_cols, \n",
    "                 lst_binary_exists, \n",
    "                 lst_binary_boolean_to_numeric, \n",
    "                 lst_json_binary, \n",
    "                 dict_transform_str_is_in, \n",
    "                 dict_inmobiliario, \n",
    "                 dict_transform_num_elements, \n",
    "                 lst_outliers)\n",
    "\n",
    "df_X_train_processed = transf_dataset.fit_transform(df_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test_processed = transf_dataset.transform(df_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_processed.to_csv(\"X_train_processed.csv\", index=False)\n",
    "df_X_test_processed.to_csv(\"X_test_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
